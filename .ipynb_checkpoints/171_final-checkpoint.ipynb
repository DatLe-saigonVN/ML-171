{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install imblearn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Plotting a histogram for each attribute\n",
    "data.hist(figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Histograms of Wine Dataset Attributes', y =1.05)\n",
    "plt.show()\n",
    "\n",
    "# Box plot for each attribute\n",
    "data.plot(kind='box', figsize=(16, 8))\n",
    "plt.tight_layout()\n",
    "plt.title('Box Plots of Wine Dataset Attributes')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(correlation_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns, rotation=90)\n",
    "plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "plt.title('Correlation Matrix of Wine Dataset Attributes')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plots of attributes vs quality\n",
    "for column in data.columns:\n",
    "    if column != 'quality':\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(data[column], data['quality'])\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel('Quality')\n",
    "        plt.title('Scatter Plot: Quality vs ' + column)\n",
    "        plt.legend(['Wine Samples'])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Dimensionality reduction with PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(data.drop('quality', axis=1))  # Exclude 'quality' from PCA\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(pca_data[:, 0], pca_data[:, 1], c=data['quality'])\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA: Dimensionality Reduction')\n",
    "plt.legend(*scatter.legend_elements(), title=\"Quality\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Summary of statistics for each attribute\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Calculate summary statistics for the dataset\n",
    "summary_stats = data.describe()\n",
    "\n",
    "# Calculate IQR for each column and append to the summary\n",
    "iqr = data.quantile(0.75) - data.quantile(0.25)\n",
    "summary_stats.loc['IQR'] = iqr\n",
    "summary_stats.to_csv('summary_stats.csv')\n",
    "# Print the summary statistics\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.20      0.20      0.20         5\n",
      "           4       0.53      0.32      0.40        25\n",
      "           5       0.69      0.71      0.70       291\n",
      "           6       0.67      0.75      0.71       432\n",
      "           7       0.73      0.58      0.65       192\n",
      "           8       0.71      0.43      0.54        35\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68       980\n",
      "   macro avg       0.51      0.43      0.46       980\n",
      "weighted avg       0.68      0.68      0.68       980\n",
      "\n",
      "Best parameters found: {'gbc__n_estimators': 500, 'gbc__max_depth': 6, 'gbc__learning_rate': 0.1}\n",
      "Best cross-validated training data score found: 0.6462456484125827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "gbc_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('gbc', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "gbc_param_grid = {\n",
    "    'gbc__n_estimators': [100, 200, 300, 400, 500],\n",
    "    'gbc__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'gbc__max_depth': [3, 4, 5, 6, 7],\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "gbc_random_search = RandomizedSearchCV(gbc_pipeline, gbc_param_grid, cv=4, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "gbc_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict and print classification report\n",
    "y_pred = gbc_random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Best parameters found:\", gbc_random_search.best_params_)\n",
    "print(\"Best cross-validated training data score found:\", gbc_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.60      0.24      0.34        25\n",
      "           5       0.75      0.70      0.72       291\n",
      "           6       0.66      0.82      0.73       432\n",
      "           7       0.79      0.59      0.67       192\n",
      "           8       0.94      0.46      0.62        35\n",
      "\n",
      "    accuracy                           0.71       980\n",
      "   macro avg       0.62      0.47      0.52       980\n",
      "weighted avg       0.72      0.71      0.70       980\n",
      "\n",
      "Test size: 0.2\n",
      "Random state: 42\n",
      "Best parameters found: {'rf__max_depth': 50, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 400}\n",
      "Best cross-validated training data score found: 0.6653882032894874\n",
      "Test dataset score: 0.7091836734693877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.33      0.14      0.20         7\n",
      "           4       0.50      0.20      0.29        40\n",
      "           5       0.68      0.73      0.71       426\n",
      "           6       0.67      0.76      0.71       668\n",
      "           7       0.72      0.57      0.63       280\n",
      "           8       0.95      0.39      0.55        49\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.64      0.46      0.51      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "Test size: 0.3\n",
      "Random state: 42\n",
      "Best parameters found: {'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 400}\n",
      "Best cross-validated training data score found: 0.6534422403733955\n",
      "Test dataset score: 0.6836734693877551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Set the test sizes and random state\n",
    "test_sizes = [0.2, 0.3]\n",
    "random_state = 42\n",
    "\n",
    "# Prepare the pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Prepare the parameter grid\n",
    "rf_param_grid = {\n",
    "    'rf__n_estimators': [100, 200, 300, 400, 500],\n",
    "    'rf__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Create a stratified K-fold cross-validator\n",
    "strat_k_fold = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# Loop over the test sizes to evaluate each\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    rf_grid_search = GridSearchCV(rf_pipeline, rf_param_grid, cv=strat_k_fold, n_jobs=-1)\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_score = rf_grid_search.best_score_\n",
    "    best_params = rf_grid_search.best_params_\n",
    "\n",
    "    best_model = rf_grid_search.best_estimator_\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Test size:\", test_size)\n",
    "    print(\"Random state:\", random_state)\n",
    "    print(\"Best parameters found:\", best_params)\n",
    "    print(\"Best cross-validated training data score found:\", best_score)\n",
    "    print(\"Test dataset score:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.50      0.14      0.22         7\n",
      "           4       0.36      0.25      0.29        40\n",
      "           5       0.63      0.68      0.65       426\n",
      "           6       0.68      0.64      0.66       668\n",
      "           7       0.59      0.62      0.60       280\n",
      "           8       0.40      0.43      0.42        49\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.45      0.39      0.41      1470\n",
      "weighted avg       0.63      0.63      0.63      1470\n",
      "\n",
      "Best parameters found: {'mlp__activation': 'tanh', 'mlp__alpha': 0.05, 'mlp__hidden_layer_sizes': (50, 50, 50), 'mlp__learning_rate': 'adaptive', 'mlp__solver': 'adam'}\n",
      "Best cross-validated training data score found: 0.5892648774795799\n",
      "Test dataset score: 0.6278911564625851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "mlp_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp', MLPClassifier(max_iter=1000))\n",
    "])\n",
    "\n",
    "mlp_param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'mlp__activation': ['tanh', 'relu'],\n",
    "    'mlp__solver': ['sgd', 'adam'],\n",
    "    'mlp__alpha': [0.0001, 0.05],\n",
    "    'mlp__learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "stratified_kfold = StratifiedKFold(n_splits=4)\n",
    "\n",
    "mlp_grid_search = GridSearchCV(mlp_pipeline, mlp_param_grid, cv=stratified_kfold, n_jobs=-1)\n",
    "mlp_grid_search.fit(X_train, y_train)\n",
    "\n",
    "mlp_best_score = mlp_grid_search.best_score_\n",
    "mlp_best_params = mlp_grid_search.best_params_\n",
    "\n",
    "mlp_best_model = mlp_grid_search.best_estimator_\n",
    "mlp_test_score = mlp_best_model.score(X_test, y_test)\n",
    "\n",
    "# Predict and print classification report\n",
    "y_pred = mlp_best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Best parameters found:\", mlp_best_params)\n",
    "print(\"Best cross-validated training data score found:\", mlp_best_score)\n",
    "print(\"Test dataset score:\", mlp_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.25      0.20      0.22         5\n",
      "           4       0.60      0.36      0.45        25\n",
      "           5       0.70      0.68      0.69       291\n",
      "           6       0.65      0.75      0.70       432\n",
      "           7       0.72      0.58      0.65       192\n",
      "           8       0.77      0.49      0.60        35\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68       980\n",
      "   macro avg       0.53      0.44      0.47       980\n",
      "weighted avg       0.68      0.68      0.67       980\n",
      "\n",
      "Best parameters found: {'gbc__n_estimators': 100, 'gbc__max_depth': 6, 'gbc__learning_rate': 0.2}\n",
      "Best cross-validated training data score found: 0.6426692689333139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "gbc_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('gbc', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "gbc_param_grid = {\n",
    "    'gbc__n_estimators': [100, 200, 300, 400, 500],\n",
    "    'gbc__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'gbc__max_depth': [3, 4, 5, 6, 7],\n",
    "}\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "stratified_kfold = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# Initialize RandomizedSearchCV with StratifiedKFold\n",
    "gbc_random_search = RandomizedSearchCV(gbc_pipeline, gbc_param_grid, cv=stratified_kfold, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "gbc_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict and print classification report\n",
    "y_pred = gbc_random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Best parameters found:\", gbc_random_search.best_params_)\n",
    "print(\"Best cross-validated training data score found:\", gbc_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.50      0.20      0.29         5\n",
      "           4       0.67      0.24      0.35        25\n",
      "           5       0.74      0.70      0.72       291\n",
      "           6       0.67      0.81      0.73       432\n",
      "           7       0.77      0.61      0.68       192\n",
      "           8       0.94      0.46      0.62        35\n",
      "\n",
      "    accuracy                           0.71       980\n",
      "   macro avg       0.71      0.50      0.56       980\n",
      "weighted avg       0.72      0.71      0.70       980\n",
      "\n",
      "Test size: 0.2\n",
      "Random state: 42\n",
      "Best parameters found: {'rf__max_depth': 45, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 3, 'rf__n_estimators': 350}\n",
      "Best cross-validated training data score found: 0.6641134748076963\n",
      "Test dataset score: 0.7071428571428572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.33      0.14      0.20         7\n",
      "           4       0.47      0.20      0.28        40\n",
      "           5       0.68      0.73      0.70       426\n",
      "           6       0.67      0.73      0.70       668\n",
      "           7       0.67      0.59      0.63       280\n",
      "           8       0.95      0.39      0.55        49\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.63      0.46      0.51      1470\n",
      "weighted avg       0.68      0.68      0.67      1470\n",
      "\n",
      "Test size: 0.3\n",
      "Random state: 42\n",
      "Best parameters found: {'rf__max_depth': 40, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2, 'rf__n_estimators': 450}\n",
      "Best cross-validated training data score found: 0.6543173862310385\n",
      "Test dataset score: 0.6755102040816326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Set the test sizes and random state\n",
    "test_sizes = [0.2, 0.3]\n",
    "random_state = 42\n",
    "\n",
    "# Prepare the pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Prepare the parameter grid\n",
    "rf_param_grid = {\n",
    "    'rf__n_estimators': [350, 400, 450],\n",
    "    'rf__max_depth': [25, 30, 35, 40, 45],\n",
    "    'rf__min_samples_split': [2, 3],\n",
    "    'rf__min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "\n",
    "# Create a stratified K-fold cross-validator\n",
    "strat_k_fold = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# Loop over the test sizes to evaluate each\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    rf_grid_search = GridSearchCV(rf_pipeline, rf_param_grid, cv=strat_k_fold, n_jobs=-1)\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_score = rf_grid_search.best_score_\n",
    "    best_params = rf_grid_search.best_params_\n",
    "\n",
    "    best_model = rf_grid_search.best_estimator_\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Test size:\", test_size)\n",
    "    print(\"Random state:\", random_state)\n",
    "    print(\"Best parameters found:\", best_params)\n",
    "    print(\"Best cross-validated training data score found:\", best_score)\n",
    "    print(\"Test dataset score:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.33      0.20      0.25         5\n",
      "           4       0.33      0.40      0.36        25\n",
      "           5       0.71      0.70      0.71       291\n",
      "           6       0.69      0.67      0.68       432\n",
      "           7       0.64      0.66      0.65       192\n",
      "           8       0.41      0.49      0.45        35\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.66       980\n",
      "   macro avg       0.45      0.45      0.44       980\n",
      "weighted avg       0.67      0.66      0.66       980\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  1   0   1   3   0   0   0]\n",
      " [  1  10  10   4   0   0   0]\n",
      " [  0  11 205  68   6   1   0]\n",
      " [  1   8  68 289  55  10   1]\n",
      " [  0   1   4  47 127  13   0]\n",
      " [  0   0   1   5  12  17   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "ROC-AUC Score:  0.7521409186282444\n",
      "Test size: 0.2\n",
      "Random state: 42\n",
      "Best parameters found: {'rf__max_depth': 50, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 300}\n",
      "Best cross-validated training data score found: 0.637567749265181\n",
      "Test dataset score: 0.6622448979591836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.20      0.14      0.17         7\n",
      "           4       0.41      0.40      0.41        40\n",
      "           5       0.67      0.72      0.69       426\n",
      "           6       0.69      0.65      0.67       668\n",
      "           7       0.60      0.62      0.61       280\n",
      "           8       0.48      0.47      0.47        49\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.44      0.43      0.43      1470\n",
      "weighted avg       0.65      0.65      0.65      1470\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  1   0   3   3   0   0   0]\n",
      " [  1  16  16   7   0   0   0]\n",
      " [  2  14 306  91  11   2   0]\n",
      " [  1   8 124 436  88  10   1]\n",
      " [  0   1   5  87 174  13   0]\n",
      " [  0   0   1   8  17  23   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "ROC-AUC Score:  0.7391600670371374\n",
      "Test size: 0.3\n",
      "Random state: 42\n",
      "Best parameters found: {'rf__max_depth': 30, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 300}\n",
      "Best cross-validated training data score found: 0.6327304550758459\n",
      "Test dataset score: 0.6503401360544218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# The rest of your imports remain the same\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Set the test sizes and random state\n",
    "test_sizes = [0.2, 0.3]\n",
    "random_state = 42\n",
    "\n",
    "rf_pipeline = imbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(k_neighbors=2, random_state=random_state)),  # reduce the number of neighbors\n",
    "    ('rf', RandomForestClassifier(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "\n",
    "# Prepare the parameter grid\n",
    "rf_param_grid = {\n",
    "    'rf__n_estimators': [100, 200, 300, 400, 500],\n",
    "    'rf__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Create a stratified K-fold cross-validator\n",
    "strat_k_fold = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# Loop over the test sizes to evaluate each\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    rf_grid_search = GridSearchCV(rf_pipeline, rf_param_grid, cv=strat_k_fold, n_jobs=-1)\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_score = rf_grid_search.best_score_\n",
    "    best_params = rf_grid_search.best_params_\n",
    "\n",
    "    best_model = rf_grid_search.best_estimator_\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Binarize the output for multiclass ROC-AUC\n",
    "    lb = LabelBinarizer()\n",
    "    y_test_bin = lb.fit_transform(y_test)\n",
    "    y_pred_bin = lb.transform(y_pred)\n",
    "\n",
    "    # Compute and print ROC-AUC\n",
    "    print(\"ROC-AUC Score: \", roc_auc_score(y_test_bin, y_pred_bin, average='weighted'))\n",
    "\n",
    "    print(\"Test size:\", test_size)\n",
    "    print(\"Random state:\", random_state)\n",
    "    print(\"Best parameters found:\", best_params)\n",
    "    print(\"Best cross-validated training data score found:\", best_score)\n",
    "    print(\"Test dataset score:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 1.6752 - accuracy: 0.4043 - val_loss: 1.2502 - val_accuracy: 0.5190\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 760us/step - loss: 1.1879 - accuracy: 0.5365 - val_loss: 1.1525 - val_accuracy: 0.5415\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 757us/step - loss: 1.1211 - accuracy: 0.5528 - val_loss: 1.1160 - val_accuracy: 0.5354\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 748us/step - loss: 1.0868 - accuracy: 0.5548 - val_loss: 1.1024 - val_accuracy: 0.5381\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 725us/step - loss: 1.0691 - accuracy: 0.5624 - val_loss: 1.0873 - val_accuracy: 0.5490\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 726us/step - loss: 1.0533 - accuracy: 0.5645 - val_loss: 1.0729 - val_accuracy: 0.5463\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 729us/step - loss: 1.0404 - accuracy: 0.5688 - val_loss: 1.0678 - val_accuracy: 0.5544\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 754us/step - loss: 1.0322 - accuracy: 0.5820 - val_loss: 1.0668 - val_accuracy: 0.5429\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 722us/step - loss: 1.0197 - accuracy: 0.5843 - val_loss: 1.0642 - val_accuracy: 0.5531\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 739us/step - loss: 1.0121 - accuracy: 0.5785 - val_loss: 1.0485 - val_accuracy: 0.5612\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 740us/step - loss: 1.0039 - accuracy: 0.5831 - val_loss: 1.0443 - val_accuracy: 0.5551\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 756us/step - loss: 0.9977 - accuracy: 0.5869 - val_loss: 1.0378 - val_accuracy: 0.5605\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 723us/step - loss: 0.9889 - accuracy: 0.5820 - val_loss: 1.0385 - val_accuracy: 0.5578\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 732us/step - loss: 0.9839 - accuracy: 0.5896 - val_loss: 1.0389 - val_accuracy: 0.5585\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 760us/step - loss: 0.9781 - accuracy: 0.5919 - val_loss: 1.0341 - val_accuracy: 0.5619\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 772us/step - loss: 0.9721 - accuracy: 0.5928 - val_loss: 1.0309 - val_accuracy: 0.5605\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 765us/step - loss: 0.9662 - accuracy: 0.5910 - val_loss: 1.0271 - val_accuracy: 0.5619\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 790us/step - loss: 0.9618 - accuracy: 0.5951 - val_loss: 1.0240 - val_accuracy: 0.5619\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 0s 795us/step - loss: 0.9539 - accuracy: 0.5954 - val_loss: 1.0325 - val_accuracy: 0.5578\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 879us/step - loss: 0.9495 - accuracy: 0.6004 - val_loss: 1.0327 - val_accuracy: 0.5565\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 775us/step - loss: 0.9452 - accuracy: 0.6120 - val_loss: 1.0214 - val_accuracy: 0.5599\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 751us/step - loss: 0.9388 - accuracy: 0.6001 - val_loss: 1.0198 - val_accuracy: 0.5667\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 760us/step - loss: 0.9328 - accuracy: 0.6056 - val_loss: 1.0244 - val_accuracy: 0.5660\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 756us/step - loss: 0.9276 - accuracy: 0.6097 - val_loss: 1.0305 - val_accuracy: 0.5537\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 770us/step - loss: 0.9239 - accuracy: 0.6149 - val_loss: 1.0318 - val_accuracy: 0.5667\n",
      "Train: 0.617, Test: 0.567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "X = data.drop('quality', axis=1).values\n",
    "y = data['quality'].values\n",
    "\n",
    "# One-hot encode the target column\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
    "model.add(Dense(32, activation='relu'))  # Hidden layer\n",
    "model.add(Dense(y.shape[1], activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,\n",
    "                    batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.652 total time=   9.2s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.518 total time=   2.4s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.486 total time=   3.4s\n",
      "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.470 total time=   2.8s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.145 total time=   2.9s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.222 total time=   3.3s\n",
      "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.168 total time=   4.1s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.672 total time=   2.2s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.607 total time=   1.7s\n",
      "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.316 total time=   2.8s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.540 total time=   2.7s\n",
      "[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.175 total time=   2.8s\n",
      "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.481 total time=   2.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.480 total time=   3.3s\n",
      "[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.145 total time=   2.8s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.471 total time=   2.9s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.866 total time=   3.0s\n",
      "[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=0.675 total time=13.1min\n",
      "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.258 total time=   2.3s\n",
      "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.278 total time=   2.4s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.629 total time=   2.6s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.645 total time=   2.5s\n",
      "[CV 3/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.526 total time=   2.0s\n",
      "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.409 total time=   1.9s\n",
      "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.442 total time=   2.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.530 total time=   2.6s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.556 total time=   2.5s\n",
      "[CV 3/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.152 total time=   2.7s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.480 total time=   1.9s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.494 total time=   1.9s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.703 total time=   3.3s\n",
      "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.174 total time=   4.3s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.590 total time=   2.9s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.363 total time=   3.8s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.150 total time=   2.9s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.322 total time=   4.5s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.840 total time=   2.6s\n",
      "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.171 total time=   3.8s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.654 total time=   2.1s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.588 total time=   1.7s\n",
      "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.288 total time=   2.6s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.518 total time=   2.6s\n",
      "[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.175 total time=   2.8s\n",
      "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.469 total time=   2.2s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.465 total time=   3.2s\n",
      "[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.145 total time=   2.8s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.458 total time=   2.7s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.855 total time=   2.8s\n",
      "[CV 1/5] END ........C=10, gamma=1, kernel=poly;, score=0.658 total time=12.0min\n",
      "[CV 1/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.166 total time=   3.6s\n",
      "[CV 2/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.163 total time=   3.6s\n",
      "[CV 3/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.175 total time=   3.9s\n",
      "[CV 4/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.171 total time=   3.6s\n",
      "[CV 5/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.171 total time=   3.6s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.777 total time=   3.1s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.771 total time=   3.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.794 total time=   3.1s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.790 total time=   3.1s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.772 total time=   2.9s\n",
      "[CV 1/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.652 total time=   8.3s\n",
      "[CV 2/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.653 total time=   8.8s\n",
      "[CV 3/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.662 total time=   8.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.662 total time=   7.9s\n",
      "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.263 total time=   2.3s\n",
      "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.272 total time=   2.4s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.634 total time=   2.5s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.636 total time=   2.6s\n",
      "[CV 2/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.497 total time=   2.1s\n",
      "[CV 5/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.516 total time=   2.0s\n",
      "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.418 total time=   1.9s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.530 total time=   2.5s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.552 total time=   2.6s\n",
      "[CV 2/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.152 total time=   2.6s\n",
      "[CV 5/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.151 total time=   2.6s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.513 total time=   1.9s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.702 total time=   3.3s\n",
      "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.175 total time=   4.3s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.598 total time=   2.8s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.354 total time=   3.9s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.152 total time=   2.8s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.327 total time=   4.4s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.843 total time=   2.5s\n",
      "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.165 total time=   3.7s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.662 total time=   2.2s\n",
      "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.595 total time=   1.8s\n",
      "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.294 total time=   2.6s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.522 total time=   2.7s\n",
      "[CV 1/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.169 total time=   2.7s\n",
      "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.459 total time=   2.1s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.463 total time=   3.4s\n",
      "[CV 1/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.145 total time=   2.9s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.448 total time=   2.8s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.856 total time=   2.8s\n",
      "[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=0.662 total time=13.1min\n",
      "[CV 5/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.645 total time=   8.9s\n",
      "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.273 total time=   2.5s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.647 total time=   2.8s\n",
      "[CV 1/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.508 total time=   2.1s\n",
      "[CV 4/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.518 total time=   2.1s\n",
      "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.404 total time=   1.8s\n",
      "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.427 total time=   2.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.545 total time=   2.7s\n",
      "[CV 1/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.147 total time=   2.8s\n",
      "[CV 4/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.150 total time=   2.7s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.496 total time=   1.9s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.510 total time=   1.7s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.696 total time=   3.1s\n",
      "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.155 total time=   4.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.575 total time=   2.8s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.347 total time=   3.8s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.147 total time=   2.8s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.326 total time=   4.4s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.218 total time=   3.3s\n",
      "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.173 total time=   3.8s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.673 total time=   1.9s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.615 total time=   1.8s\n",
      "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.311 total time=   2.9s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.541 total time=   2.7s\n",
      "[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.175 total time=   2.6s\n",
      "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.470 total time=   2.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.470 total time=   3.5s\n",
      "[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.145 total time=   2.8s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.473 total time=   2.9s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.868 total time=   3.0s\n",
      "[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=0.679 total time=13.9min\n",
      "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.662 total time=   8.5s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.508 total time=   2.3s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.364 total time=   3.8s\n",
      "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.445 total time=   2.7s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.334 total time=   4.5s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.824 total time=   2.7s\n",
      "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.171 total time=   3.9s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.670 total time=   2.1s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.597 total time=   1.7s\n",
      "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.315 total time=   2.8s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.546 total time=   2.9s\n",
      "[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.177 total time=   2.7s\n",
      "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.486 total time=   2.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.487 total time=   3.5s\n",
      "[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.145 total time=   2.9s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.471 total time=   2.8s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.854 total time=   3.1s\n",
      "[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=0.664 total time=15.2min\n",
      "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.662 total time=   8.7s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.497 total time=   2.5s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.473 total time=   3.4s\n",
      "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.455 total time=   2.7s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.145 total time=   2.8s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.227 total time=   3.3s\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.658 total time= 1.3min\n",
      "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.174 total time=   4.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.729 total time=   2.1s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.735 total time=   2.1s\n",
      "[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.633 total time=   2.5s\n",
      "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.275 total time=   2.7s\n",
      "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.285 total time=   2.9s\n",
      "[CV 1/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.284 total time=   2.8s\n",
      "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.444 total time=   2.1s\n",
      "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.471 total time=   2.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.513 total time=   2.9s\n",
      "[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.145 total time=   2.9s\n",
      "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.497 total time=   2.1s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.853 total time=   3.0s\n",
      "[CV 5/5] END ......C=100, gamma=1, kernel=poly;, score=0.664 total time=127.0min\n",
      "Best parameters for test size 0.2: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Classification Report for test size 0.2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.98      1.00      0.99       428\n",
      "           4       0.94      0.97      0.95       434\n",
      "           5       0.80      0.76      0.78       469\n",
      "           6       0.69      0.70      0.69       446\n",
      "           7       0.85      0.82      0.83       432\n",
      "           8       0.94      0.97      0.95       453\n",
      "           9       1.00      1.00      1.00       416\n",
      "\n",
      "    accuracy                           0.88      3078\n",
      "   macro avg       0.89      0.89      0.89      3078\n",
      "weighted avg       0.88      0.88      0.88      3078\n",
      "\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.650 total time=   7.2s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.369 total time=   3.3s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.148 total time=   2.2s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.370 total time=   3.3s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.193 total time=   2.6s\n",
      "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.178 total time=   2.8s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.649 total time=   1.6s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.603 total time=   1.3s\n",
      "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.311 total time=   2.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.522 total time=   2.1s\n",
      "[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.174 total time=   2.1s\n",
      "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.463 total time=   1.6s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.468 total time=   2.6s\n",
      "[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.144 total time=   2.3s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.457 total time=   2.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.856 total time=   2.2s\n",
      "[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=0.657 total time=10.0min\n",
      "[CV 1/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.173 total time=   2.9s\n",
      "[CV 3/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.152 total time=   2.6s\n",
      "[CV 5/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.174 total time=   2.6s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.778 total time=   2.4s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.783 total time=   2.4s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.768 total time=   2.3s\n",
      "[CV 2/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.649 total time=   6.7s\n",
      "[CV 4/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.669 total time=   6.7s\n",
      "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.270 total time=   1.8s\n",
      "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.276 total time=   1.7s\n",
      "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.283 total time=   1.9s\n",
      "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.281 total time=   1.7s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.625 total time=   1.9s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.653 total time=   1.9s\n",
      "[CV 1/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.489 total time=   1.6s\n",
      "[CV 3/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.515 total time=   1.5s\n",
      "[CV 5/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.505 total time=   1.5s\n",
      "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.404 total time=   1.5s\n",
      "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.434 total time=   1.5s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.540 total time=   2.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.540 total time=   1.8s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.549 total time=   2.1s\n",
      "[CV 2/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.152 total time=   2.1s\n",
      "[CV 4/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.149 total time=   2.2s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.498 total time=   1.5s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.490 total time=   1.5s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.508 total time=   1.4s\n",
      "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.652 total time=   9.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.526 total time=   2.5s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.484 total time=   3.4s\n",
      "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.468 total time=   2.7s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.145 total time=   2.7s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.223 total time=   3.3s\n",
      "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.659 total time= 1.4min\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.724 total time=   2.2s\n",
      "[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.644 total time=   2.5s\n",
      "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.284 total time=   2.8s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.567 total time=   2.7s\n",
      "[CV 2/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.289 total time=   2.7s\n",
      "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.450 total time=   2.2s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.502 total time=   3.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.145 total time=   2.9s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.481 total time=   2.1s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.857 total time=   2.9s\n",
      "[CV 2/5] END ......C=100, gamma=1, kernel=poly;, score=0.659 total time=131.9min\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.696 total time=   2.6s\n",
      "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.164 total time=   2.9s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.576 total time=   2.4s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.503 total time=   1.8s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.475 total time=   2.8s\n",
      "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.455 total time=   2.3s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.144 total time=   2.2s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.188 total time=   2.5s\n",
      "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.161 total time=   2.9s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.668 total time=   1.6s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.617 total time=   1.3s\n",
      "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.306 total time=   2.2s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.545 total time=   2.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.174 total time=   2.3s\n",
      "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.479 total time=   1.7s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.477 total time=   2.7s\n",
      "[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.144 total time=   2.2s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.461 total time=   2.1s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.854 total time=   2.3s\n",
      "[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=0.672 total time=10.0min\n",
      "[CV 2/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.146 total time=   2.7s\n",
      "[CV 4/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.186 total time=   2.8s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.773 total time=   2.5s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.786 total time=   2.5s\n",
      "[CV 1/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.650 total time=   6.9s\n",
      "[CV 3/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.665 total time=   6.8s\n",
      "[CV 5/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.643 total time=   6.7s\n",
      "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.281 total time=   1.8s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.634 total time=   1.8s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.642 total time=   2.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.633 total time=   1.9s\n",
      "[CV 2/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.503 total time=   1.5s\n",
      "[CV 4/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.514 total time=   1.5s\n",
      "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.413 total time=   1.4s\n",
      "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.428 total time=   1.5s\n",
      "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.425 total time=   1.7s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.531 total time=   1.9s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.553 total time=   2.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.148 total time=   2.3s\n",
      "[CV 3/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.152 total time=   2.3s\n",
      "[CV 5/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.149 total time=   2.1s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.503 total time=   1.5s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.504 total time=   1.4s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.707 total time=   3.3s\n",
      "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.168 total time=   4.1s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.570 total time=   2.8s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.355 total time=   3.8s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.152 total time=   2.7s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.323 total time=   4.5s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.823 total time=   2.5s\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.659 total time= 1.6min\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.602 total time=   2.6s\n",
      "[CV 4/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.284 total time=   3.0s\n",
      "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.470 total time=   2.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.508 total time=   3.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.145 total time=   2.8s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.488 total time=   2.1s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.863 total time=   2.9s\n",
      "[CV 4/5] END ......C=100, gamma=1, kernel=poly;, score=0.681 total time=134.9min\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.709 total time=   2.4s\n",
      "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.164 total time=   3.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.568 total time=   2.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.489 total time=   1.8s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.480 total time=   2.9s\n",
      "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.457 total time=   2.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.384 total time=   3.3s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.819 total time=   2.0s\n",
      "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.169 total time=   2.9s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.656 total time=   1.7s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.589 total time=   1.4s\n",
      "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.316 total time=   2.2s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.534 total time=   2.1s\n",
      "[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.168 total time=   2.1s\n",
      "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.481 total time=   1.7s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.484 total time=   2.7s\n",
      "[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.144 total time=   2.2s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.455 total time=   2.2s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.852 total time=   2.3s\n",
      "[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=0.651 total time=12.8min\n",
      "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.669 total time=   7.4s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.357 total time=   3.2s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.152 total time=   2.1s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.369 total time=   3.2s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.188 total time=   2.4s\n",
      "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.176 total time=   3.1s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.679 total time=   1.5s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.614 total time=   1.2s\n",
      "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.318 total time=   2.1s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.539 total time=   2.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.171 total time=   2.3s\n",
      "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.472 total time=   1.7s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.481 total time=   2.7s\n",
      "[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.144 total time=   2.2s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.458 total time=   2.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.841 total time=   2.1s\n",
      "[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=0.688 total time=13.0min\n",
      "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.643 total time=   7.9s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.368 total time=   3.1s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.149 total time=   2.2s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.386 total time=   3.1s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.836 total time=   2.0s\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.649 total time= 1.1min\n",
      "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.187 total time=   3.1s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.740 total time=   2.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.646 total time=   2.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.286 total time=   2.2s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.603 total time=   2.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.316 total time=   2.7s\n",
      "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.474 total time=   1.9s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.504 total time=   2.3s\n",
      "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.144 total time=   2.2s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.487 total time=   1.6s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.838 total time=   2.2s\n",
      "[CV 4/5] END .......C=100, gamma=1, kernel=poly;, score=0.673 total time=88.3min\n",
      "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.644 total time=  11.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.473 total time=   3.5s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.151 total time=   2.8s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.145 total time=   2.9s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.225 total time=   3.4s\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.666 total time= 1.3min\n",
      "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.169 total time=   3.8s\n",
      "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.171 total time=   4.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.736 total time=   2.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.655 total time=   2.4s\n",
      "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.264 total time=   2.9s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.575 total time=   2.8s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.602 total time=   2.4s\n",
      "[CV 5/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.293 total time=   3.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.483 total time=   2.9s\n",
      "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.145 total time=   2.9s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.465 total time=   2.2s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.853 total time=   2.9s\n",
      "[CV 1/5] END ......C=100, gamma=1, kernel=poly;, score=0.662 total time=133.2min\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.695 total time=   2.6s\n",
      "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.168 total time=   3.1s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.587 total time=   2.4s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.514 total time=   1.9s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.489 total time=   2.8s\n",
      "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.461 total time=   2.1s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.144 total time=   2.3s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.824 total time=   2.0s\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.679 total time=  56.4s\n",
      "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.180 total time=   2.9s\n",
      "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.147 total time=   2.7s\n",
      "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.154 total time=   2.9s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.717 total time=   1.8s\n",
      "[CV 1/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.636 total time=   2.1s\n",
      "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.274 total time=   2.3s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.578 total time=   2.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.302 total time=   2.5s\n",
      "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.454 total time=   1.9s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.497 total time=   2.6s\n",
      "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.144 total time=   2.2s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.481 total time=   1.7s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.855 total time=   2.3s\n",
      "[CV 2/5] END .......C=100, gamma=1, kernel=poly;, score=0.659 total time=88.7min\n",
      "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.649 total time=   8.2s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.370 total time=   3.1s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.149 total time=   2.1s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.144 total time=   2.2s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.183 total time=   2.5s\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.656 total time= 1.1min\n",
      "[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.630 total time=   2.1s\n",
      "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.279 total time=   2.3s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.568 total time=   2.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.286 total time=   2.5s\n",
      "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.450 total time=   2.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.495 total time=   2.6s\n",
      "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.144 total time=   2.2s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.472 total time=   1.6s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.852 total time=   2.2s\n",
      "[CV 1/5] END .......C=100, gamma=1, kernel=poly;, score=0.659 total time=93.7min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(svm, param_grid, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Fit the grid\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Print the best parameters\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for test size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Perform Pearson correlation and select top 10 features\n",
    "correlation = df.corr()['quality'].sort_values(ascending=False)\n",
    "top_features = correlation.index[1:11]  # Excluding 'quality' itself\n",
    "\n",
    "# Drop 'residual sugar' and 'free sulfur dioxide' (if they are in top_features)\n",
    "if 'residual sugar' in top_features:\n",
    "    top_features = top_features.drop('residual sugar')\n",
    "if 'free sulfur dioxide' in top_features:\n",
    "    top_features = top_features.drop('free sulfur dioxide')\n",
    "\n",
    "X = df[top_features]\n",
    "y = df['quality']\n",
    "\n",
    "# Get the count of the least represented class\n",
    "min_class_count = y.value_counts().min()\n",
    "\n",
    "# Use SMOTE to oversample the minority classes\n",
    "smote = SMOTE(k_neighbors=min_class_count-1 if min_class_count > 1 else 1, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# List of test sizes\n",
    "test_sizes = [0.2, 0.3]\n",
    "\n",
    "# Parameters for grid search\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize an SVM model\n",
    "    svm = SVC()\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid = GridSearchCV(svm, param_grid, refit=True, verbose=3, n_jobs=-1)\n",
    "\n",
    "    # Fit the grid\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(f\"Best parameters for test size {test_size}: {grid.best_params_}\")\n",
    "\n",
    "    # Make predictions with the best parameters and evaluate the model\n",
    "    y_pred = grid.predict(X_test)\n",
    "    print(f\"Classification Report for test size {test_size}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test size 0.2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.43      0.12      0.19        25\n",
      "           5       0.68      0.68      0.68       291\n",
      "           6       0.64      0.76      0.70       432\n",
      "           7       0.74      0.57      0.64       192\n",
      "           8       0.78      0.40      0.53        35\n",
      "\n",
      "    accuracy                           0.67       980\n",
      "   macro avg       0.54      0.42      0.46       980\n",
      "weighted avg       0.67      0.67      0.66       980\n",
      "\n",
      "Best parameters found: {'rf__n_estimators': 50, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 1, 'rf__max_depth': 40}\n",
      "Best cross-validated training data score found: 0.6332312404287902\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test size 0.3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.33      0.05      0.09        40\n",
      "           5       0.68      0.69      0.69       426\n",
      "           6       0.64      0.77      0.70       668\n",
      "           7       0.69      0.52      0.59       280\n",
      "           8       0.74      0.29      0.41        49\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.51      0.39      0.41      1470\n",
      "weighted avg       0.65      0.66      0.64      1470\n",
      "\n",
      "Best parameters found: {'rf__n_estimators': 50, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 2, 'rf__max_depth': 20}\n",
      "Best cross-validated training data score found: 0.618433021324757\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Correlation Analysis\n",
    "correlation = data.corr()['quality'].drop('quality')\n",
    "relevant_features = correlation[correlation.abs() > 0.05]\n",
    "\n",
    "X = data[relevant_features.index]\n",
    "y = data['quality']\n",
    "\n",
    "# Define test sizes\n",
    "test_sizes = [0.2, 0.3]\n",
    "\n",
    "# Initialize pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "rf_param_grid = {\n",
    "    'rf__n_estimators': [10, 50, 100, 200],\n",
    "    'rf__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Initialize RandomizedSearchCV\n",
    "    rf_random_search = RandomizedSearchCV(rf_pipeline, rf_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "    # Fit RandomizedSearchCV to the training data\n",
    "    rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and print classification report\n",
    "    y_pred = rf_random_search.predict(X_test)\n",
    "    print(f\"Classification Report for test size {test_size}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Best parameters found:\", rf_random_search.best_params_)\n",
    "    print(\"Best cross-validated training data score found:\", rf_random_search.best_score_)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test size 0.2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.75      0.12      0.21        25\n",
      "           5       0.93      0.39      0.55       291\n",
      "           6       0.56      0.98      0.71       432\n",
      "           7       0.99      0.42      0.59       192\n",
      "           8       1.00      0.40      0.57        35\n",
      "\n",
      "    accuracy                           0.65       980\n",
      "   macro avg       0.71      0.39      0.44       980\n",
      "weighted avg       0.77      0.65      0.62       980\n",
      "\n",
      "Best parameters found: {'svm__kernel': 'rbf', 'svm__gamma': 10.0, 'svm__C': 10.0}\n",
      "Best cross-validated training data score found: 0.587034201123022\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test size 0.3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       1.00      0.05      0.10        40\n",
      "           5       1.00      0.29      0.45       426\n",
      "           6       0.54      1.00      0.70       668\n",
      "           7       1.00      0.31      0.47       280\n",
      "           8       1.00      0.35      0.52        49\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.76      0.33      0.37      1470\n",
      "weighted avg       0.79      0.61      0.56      1470\n",
      "\n",
      "Best parameters found: {'svm__kernel': 'rbf', 'svm__gamma': 100.0, 'svm__C': 1.0}\n",
      "Best cross-validated training data score found: 0.5504678596436392\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/miniconda3/envs/MLbasics/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Correlation Analysis\n",
    "correlation = data.corr()['quality'].drop('quality')\n",
    "relevant_features = correlation[correlation.abs() > 0.05]\n",
    "\n",
    "X = data[relevant_features.index]\n",
    "y = data['quality']\n",
    "\n",
    "# Define test sizes\n",
    "test_sizes = [0.2, 0.3]\n",
    "\n",
    "# Initialize pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "svm_param_grid = {\n",
    "    'svm__C': np.logspace(-3, 2, num=6),\n",
    "    'svm__kernel': ['linear', 'rbf'],\n",
    "    'svm__gamma': np.logspace(-3, 2, num=6)\n",
    "}\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Initialize RandomizedSearchCV\n",
    "    svm_random_search = RandomizedSearchCV(svm_pipeline, svm_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "    # Fit RandomizedSearchCV to the training data\n",
    "    svm_random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and print classification report\n",
    "    y_pred = svm_random_search.predict(X_test)\n",
    "    print(f\"Classification Report for test size {test_size}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Best parameters found:\", svm_random_search.best_params_)\n",
    "    print(\"Best cross-validated training data score found:\", svm_random_search.best_score_)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load your data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinequality-white.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Perform Pearson correlation and select top 10 features\n",
    "correlation = df.corr()['quality'].sort_values(ascending=False)\n",
    "top_features = correlation.index[1:11]  # Excluding 'quality' itself\n",
    "\n",
    "# Drop 'residual sugar' and 'free sulfur dioxide' (if they are in top_features)\n",
    "if 'residual sugar' in top_features:\n",
    "    top_features = top_features.drop('residual sugar')\n",
    "if 'free sulfur dioxide' in top_features:\n",
    "    top_features = top_features.drop('free sulfur dioxide')\n",
    "\n",
    "X = df[top_features]\n",
    "y = df['quality']\n",
    "\n",
    "# Get the count of the least represented class\n",
    "min_class_count = y.value_counts().min()\n",
    "\n",
    "# Use SMOTE to oversample the minority classes\n",
    "smote = SMOTE(k_neighbors=min_class_count-1 if min_class_count > 1 else 1, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# List of test sizes\n",
    "test_sizes = [0.2, 0.3]\n",
    "\n",
    "# Parameters for grid search\n",
    "param_grid = {'n_neighbors': list(range(1,31)),\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'metric': ['euclidean', 'manhattan', 'minkowski']}\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize a KNN model\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid = GridSearchCV(knn, param_grid, refit=True, verbose=3, n_jobs=-1)\n",
    "\n",
    "    # Fit the grid\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(f\"Best parameters for test size {test_size}: {grid.best_params_}\")\n",
    "\n",
    "    # Make predictions with the best parameters and evaluate the model\n",
    "    y_pred = grid.predict(X_test)\n",
    "    print(f\"Classification Report for test size {test_size}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
